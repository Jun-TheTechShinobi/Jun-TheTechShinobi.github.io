<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Debian on Tech Shinobi</title>
    <link>https://techshinobi.org/tags/debian/</link>
    <description>Recent content in Debian on Tech Shinobi</description>
    <generator>Hugo -- 0.147.1</generator>
    <language>en</language>
    <lastBuildDate>Mon, 26 May 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://techshinobi.org/tags/debian/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Migrating Harbor instance from Linux to WSL2</title>
      <link>https://techshinobi.org/posts/harbor-wsl/</link>
      <pubDate>Mon, 26 May 2025 00:00:00 +0000</pubDate>
      <guid>https://techshinobi.org/posts/harbor-wsl/</guid>
      <description>&lt;p&gt;In the past, I have covered how to set up &lt;a href=&#34;https://techshinobi.org/posts/wsl2/&#34;&gt;Ubuntu in WSL2&lt;/a&gt; and &lt;a href=&#34;https://techshinobi.org/posts/easy-local-llm/#docker--harbor&#34;&gt;hosting local LLMs with Harbor&lt;/a&gt;, now I want to migrate my Harbor instance from baremetal Linux into WSL2 so that I don&amp;rsquo;t have to set it up from scratch.&lt;/p&gt;
&lt;p&gt;First thing to do is to &lt;a href=&#34;https://learn.microsoft.com/en-us/windows/wsl/networking&#34;&gt;open firewall port&lt;/a&gt;&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;netsh interface portproxy add v4tov4 listenport=33811 listenaddress=0.0.0.0 connectport=33801 connectaddress=172.xx.xxx.xxx
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;On Linux hardware: copy Harbor files from&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;/home/username/Harbor
/home/username/.ollama
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;On Windows hardware: connect the USB drive containing Harbor files and run&lt;/p&gt;</description>
    </item>
    <item>
      <title>Self-hosting Local LLMs (DeepSeek-R1) Easily with Harbor (Ollama&#43;Open-WebUI&#43;SearXNG)</title>
      <link>https://techshinobi.org/posts/easy-local-llm/</link>
      <pubDate>Sun, 26 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://techshinobi.org/posts/easy-local-llm/</guid>
      <description>&lt;p&gt;Lately, there is a need of private chatbot service as a complete alternative to OpenAI&amp;rsquo;s ChatGPT. So, I decide to implement one at home and make it accessible to everyone in my household alongside with my network printer and NAS (OpenMediaVault).&lt;/p&gt;
&lt;p&gt;In the past, I used to recommend people using Llama series for English tasks and Qwen series for Chinese tasks. There was no open-source model that&amp;rsquo;s strong enough in multilingual tasks comparing to proprietary ones (GPT/Claude).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cheapskate&#39;s Homebrew AI Lab</title>
      <link>https://techshinobi.org/posts/cheapai/</link>
      <pubDate>Mon, 23 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://techshinobi.org/posts/cheapai/</guid>
      <description>&lt;h2 id=&#34;old-stories&#34;&gt;Old Stories&lt;/h2&gt;
&lt;p&gt;The computer hardware used to be more playful and worth tinkering. My favorate platfom from a decade ago, Sandy Bridge on LGA 1155, can still be powerful even today.&lt;/p&gt;
&lt;p&gt;Back in the days, I used to repair people&amp;rsquo;s electronics for free. Because of that, I also received a lots of spares and e-waste in exchange. One of the best was a LGA 1155 motherboard with i5-2300 on it. Then, I bought a cheap E3-1245 and GTX 750 Ti to make it a gaming rig. I played a lot of games on that, such as Dark Souls series and Metro series. Before it was sold, last games I played on this build was Metro Exodus and Elden Ring.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cheapskate&#39;s Stable Diffusion Server</title>
      <link>https://techshinobi.org/posts/cheapsd/</link>
      <pubDate>Tue, 28 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://techshinobi.org/posts/cheapsd/</guid>
      <description>&lt;h2 id=&#34;no-dall-e-no-midjourney-and-no-colab&#34;&gt;No DALL-E, No Midjourney and No Colab&lt;/h2&gt;
&lt;p&gt;This is a guide showing how to build your own stable diffusion server on what you already have or cheap used hardwares. It may not satisfy for a serious production use but pretty viable for learning, testing or casual use.&lt;/p&gt;
&lt;p&gt;Before we start, here&amp;rsquo;s some comments on OpenAI:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.businessinsider.com/history-of-openai-company-chatgpt-elon-musk-founded-2022-12&#34;&gt;The history of ChatGPT creator OpenAI, which Elon Musk helped found before parting ways and criticizing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.vice.com/en/article/5d3naz/openai-is-now-everything-it-promised-not-to-be-corporate-closed-source-and-for-profit&#34;&gt;OpenAI Is Now Everything It Promised Not to Be: Corporate, Closed-Source, and For-Profit&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scribe.nixnet.services/geekculture/will-chatgpt-be-open-source-4b2928d57a2&#34;&gt;Will ChatGPT be open source?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.theregister.com/2023/03/24/column/&#34;&gt;ChatGPT, how did you get here? It was a long journey through open source AI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tcrn.ch/3MKBD5P&#34;&gt;When big AI labs refuse to open source their models, the community steps in&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://youtu.be/Sqa8Zo2XWc4&#34;&gt;Artificial Intelligence: Last Week Tonight with John Oliver (HBO)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://youtu.be/hZTv-R6E32Y&#34;&gt;The TRUTH about OpenAI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I have been using ChatGPT and its API regulary. Since my &lt;a href=&#34;https://techshinobi.org/posts/bypass-chatgpt/&#34;&gt;last post&lt;/a&gt;, the API has been upgraded to gpt-3.5-turbo which broke my program and gpt-4 seems coming up soon. Therefore, I may not fix my code proactively.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
