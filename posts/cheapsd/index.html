<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Cheapskate&#39;s Stable Diffusion Server | Tech Shinobi</title>
<meta name="keywords" content="StableDiffusion, Cheapskate, OpenAI, Opensource, ChatGPT, API, AUTOMATIC1111, debian, script, Self-Healing, hardware">
<meta name="description" content="No DALL-E, No Midjourney and No Colab This is a guide showing how to build your own stable diffusion server on what you already have or cheap used hardwares. It may not satisfy for a serious production use but pretty viable for learning, testing or casual use.
Before we start, here&rsquo;s some comments on OpenAI:
 The history of ChatGPT creator OpenAI, which Elon Musk helped found before parting ways and criticizing OpenAI Is Now Everything It Promised Not to Be: Corporate, Closed-Source, and For-Profit Will ChatGPT be open source?">
<meta name="author" content="Jun">
<link rel="canonical" href="https://techshinobi.org/posts/cheapsd/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.48a18943c2fc15c38a372b8dde1f5e5dc0bc64fa6cb90f5a817d2f8c76b7f3ae.css" integrity="sha256-SKGJQ8L8FcOKNyuN3h9eXcC8ZPpsuQ9agX0vjHa3864=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.e85ad0406048e8176e1c7661b25d5c69297ddfe41dc4124cf75ecb99a4f7b3d1.js" integrity="sha256-6FrQQGBI6BduHHZhsl1caSl93&#43;QdxBJM917LmaT3s9E="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://techshinobi.org/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://techshinobi.org/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://techshinobi.org/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://techshinobi.org/apple-touch-icon.png">
<link rel="mask-icon" href="https://techshinobi.org/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><meta property="og:title" content="Cheapskate&#39;s Stable Diffusion Server" />
<meta property="og:description" content="No DALL-E, No Midjourney and No Colab This is a guide showing how to build your own stable diffusion server on what you already have or cheap used hardwares. It may not satisfy for a serious production use but pretty viable for learning, testing or casual use.
Before we start, here&rsquo;s some comments on OpenAI:
 The history of ChatGPT creator OpenAI, which Elon Musk helped found before parting ways and criticizing OpenAI Is Now Everything It Promised Not to Be: Corporate, Closed-Source, and For-Profit Will ChatGPT be open source?" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://techshinobi.org/posts/cheapsd/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-03-28T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2023-03-28T00:00:00&#43;00:00" /><meta property="og:site_name" content="TechShinobi" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Cheapskate&#39;s Stable Diffusion Server"/>
<meta name="twitter:description" content="No DALL-E, No Midjourney and No Colab This is a guide showing how to build your own stable diffusion server on what you already have or cheap used hardwares. It may not satisfy for a serious production use but pretty viable for learning, testing or casual use.
Before we start, here&rsquo;s some comments on OpenAI:
 The history of ChatGPT creator OpenAI, which Elon Musk helped found before parting ways and criticizing OpenAI Is Now Everything It Promised Not to Be: Corporate, Closed-Source, and For-Profit Will ChatGPT be open source?"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://techshinobi.org/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Cheapskate's Stable Diffusion Server",
      "item": "https://techshinobi.org/posts/cheapsd/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Cheapskate's Stable Diffusion Server",
  "name": "Cheapskate\u0027s Stable Diffusion Server",
  "description": "No DALL-E, No Midjourney and No Colab This is a guide showing how to build your own stable diffusion server on what you already have or cheap used hardwares. It may not satisfy for a serious production use but pretty viable for learning, testing or casual use.\nBefore we start, here\u0026rsquo;s some comments on OpenAI:\n The history of ChatGPT creator OpenAI, which Elon Musk helped found before parting ways and criticizing OpenAI Is Now Everything It Promised Not to Be: Corporate, Closed-Source, and For-Profit Will ChatGPT be open source?",
  "keywords": [
    "StableDiffusion", "Cheapskate", "OpenAI", "Opensource", "ChatGPT", "API", "AUTOMATIC1111", "debian", "script", "Self-Healing", "hardware"
  ],
  "articleBody": "No DALL-E, No Midjourney and No Colab This is a guide showing how to build your own stable diffusion server on what you already have or cheap used hardwares. It may not satisfy for a serious production use but pretty viable for learning, testing or casual use.\nBefore we start, here’s some comments on OpenAI:\n The history of ChatGPT creator OpenAI, which Elon Musk helped found before parting ways and criticizing OpenAI Is Now Everything It Promised Not to Be: Corporate, Closed-Source, and For-Profit Will ChatGPT be open source? ChatGPT, how did you get here? It was a long journey through open source AI When big AI labs refuse to open source their models, the community steps in Artificial Intelligence: Last Week Tonight with John Oliver (HBO) The TRUTH about OpenAI  I have been using ChatGPT and its API regulary. Since my last post, the API has been upgraded to gpt-3.5-turbo which broke my program and gpt-4 seems coming up soon. Therefore, I may not fix my code proactively.\nI also built a customized chatbot project which was running on the web version of ChatGPT. However, one day it suddenly got blocked by OpenAI’s cloudflare filter.\nI believe that was done on purpose —by tightening up the IP range of all popular VPN providers. I have to switch over to a proxy login endpoint https://bypass.duti.tech/api/, thanks to acheong08’s Reverse engineered ChatGPT API. By doing this, it compromises some of security but it’s better than using the paid API.\nThe reason why I keep trying this route is not just for saving money, but to counter attack against the Big Tech companies.\nThere are a list of alternatives to OpenAI’s GPT. I would like to test llama.cpp sometime, as it can run on as low-profile as a Raspberry Pi.\nThe stand I’m taking is simple. I love the technology but I have problem with big tech company. I’ll work against it unless the product goes truly open source and their business model goes nonprofit —because neutrality and transparency is crucial for such technology.\nAI itself is not a threat but the capital behind it.\nHardware Requirements This article is for both old GPUs and CPU. If using a GPU, make sure it supports FP16. Otherwise, just run it on CPU regardless because it will run into VRAM issues.\n 2GB or larger Nvidia card of Maxwell 1 (745, 750, and 750ti)\n According to this buying guide, my spare GTX 750 Ti with 2GB VRAM is the oldest GPU that supports FP16.\nRAM size should be larger than 8GB. According to my test, 4GB won’t even run and 8GB works only with small models. So 12~16GB is the minimum for non-testing.\nHard drive is not important, minimum is 20GB (debian clean install + base sd-webui + 2 pruned models).\nUsing SSD can increase the speed of loading weights (switching models) but not the generating speed.\nMy mini Server Build Because of the 2GB VRAM on 750ti is barely enough for real production (Restore faces+Hires. fix+VAE+LoRA+multi-ControlNet+inpainting+upscaling). After working for hours, SD crashes quite often. Therefore, I had to heavily rely on my Self-Healing Daemon.\nFinally, I decided to build a dedicated GPU server which is smaller and more capable for various AI projects.\n HP Z2 G4 Mini Workstation - $85  Barebones w/o AC adapter C246 Chipset w/ P600 Mobile GPU (rare 4GB version)   HP 230W Power Supply - $18  19.5V 11.8A 7.4mm x 5.0mm Connector HSTNN-xxxx for EliteBook Mobile Workstations   Intel Pentium Gold G5420 $22  3.8 GHz 2 cores 4 threads 54W LGA1151 revision 2 for Coffee Lake   Spare RAM sticks - $0/$40  DDR4 16+4GB 2133MHz SODIMM   Spare SSD - $0/$30  512GB NVMe M.2 2280    Total cost for me is about $120. For buying everything from scratch would be around $200.\nNote:\n These are all used parts on ebay, so price and availability changes quite a bit. Performance should be similar between different Pascal mobile GPUs, e.g. Quadro P500, P520, P600, P620, P1000, MX1x0 and GTX10x0. Even between Maxwell (750ti) and Pascal (P600), I don’t gain noticible speed improvement but doubled VRAM for capability. CPU does not matter for SD running on GPU mode. So Pentium/Celeron is good enough for generating images. However, using tensorflow based tools like Dreambooth (for training) requires CPU to support AVX Instructions. In this case, i3-8100 or Xeon E-2124 (more $$) can be considered, however, software workaround is also available for tinkers. Although I don’t intend to do any training on this build. Creativity takes time to think and plan before take the shot. People who like spray and pray tend to spend more and hope for the best but it’s far from the way. Both bolt-action and full-auto have their value, but I’d perfer doing it just right.  Asuka Benchmark If you don’t understand the naming, never mind, it’s just the “hello world” test for SD, a.k.a. “hello asuka” test.\nThis was the gold standard in the community.\nSampler: Euler Seed: 2870305590 CFG: 12 Resolution: 512x512 Prompt: masterpiece, best quality, masterpiece, asuka langley sitting cross legged on a chair Negative Prompt: lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts,signature, watermark, username, blurry, artist name Results:\n Run on Quadro P600 (384CUDA4G) - 0:56 per asuka, 2.80s/it Run on GTX 750 Ti (640CUDA2G) - 1:09 per asuka, 3.47s/it Run on E5-2670 (8C16T) - 3:45 per asuka, 10s/it Run on E3-1245 (4C8T) - 5:30 per asuka, 16s/it Run on i5-2300 (4C4T) - 6:40 per asuka, 20s/it Run on i5-2520M (2C4T) - 12:30 per asuka, 37s/it Run on G5420 (2C4T) - 12:50 per asuka, 38s/it  Installation Debian Linux Why Linux?\nBecause it runs efficient and open-source.\nWhy Debian?\nI’ve tried RPM distros and that didn’t went well. Then I found the script says:\n Tested on Debian 11 (Bullseye)\n So just go to debian.org and get debian-11.6.0-amd64-netinst.iso\nUse Etcher or Rufus to flash the ISO file into a USB drive\nBoot into the USB installer we just created and select Graphical install\nBefore going into the network configuring step, connect the Ethernet cable so this can let it configure network interfaces automatically.\nAfter setup root and user credentials, I used entire disk while partitioning since this device is dedicated for SD.\nOther steps are good by default. Except software selection.\nDo not install any desktop environment since it may cause trouble while installing graphics driver later on.\nEnable SSH server because we want to use SD from other machines within a local network.\nWhile installing GRUB, in my case the HDD is /dev/sda.\nAfter installation finish and reboot, log in with root account.\nRun apt-get install sudo -y then usermod -aG sudo username to add the user account as sudoer. Reboot to apply this change.\nRun ip a to get the IP address, in my case the ethernet is enp0s25.\nUse mRemoteNG, Remmina or terminal to SSH into the SD dedicated machine from a daily driver computer.\nInstall the dependencies:\napt install wget git python3 python3-venv libgl1 git-lfs libglib2.0-0 Troubleshooting NIC If the ethernet doesn’t work, saying something like “Missing firmware rtl81xxxxx.fw”, then we will need to install firmware-realtek driver package.\nDownload firmware-realtek_20210315-3_all.deb from another machine, copy it to a USB drive and plug in.\nRun lsblk to confirm the USB drive is sdb1 then\nmount /dev/sdb1 /mnt\ncd /mnt\napt install /mnt/firmware-realtek_20210315-3_all.deb\nAfter installing the driver, we need to make sure the network config is right.\nnano /etc/network/interfaces\nauto enp2s0 allow-hotplug eth0 iface enp2s0 inet dhcp Run systemctl restart networking then ip a the network connection should be working now.\nUse umount /mnt to eject the USB drive.\nNVIDIA Driver and CUDA Toolkit I didn’t follow debian wiki to install the driver. By that way, it will install stable version 470 but we can install latest 530 with CUDA Toolkit.\nwget https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda_12.1.0_530.30.02_linux.run apt install linux-headers-`uname -r` build-essential libglu1-mesa-dev libx11-dev libxi-dev libxmu-dev -y chmod +x cuda_12.1.0_530.30.02_linux.run sh cuda_12.1.0_530.30.02_linux.run Select Driver and Toolkit, after installation run nvidia-smi to verify:\n+---------------------------------------------------------------------------------------+ | NVIDIA-SMI 530.30.02 Driver Version: 530.30.02 CUDA Version: 12.1 | |-----------------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |=========================================+======================+======================| | 0 NVIDIA GeForce GTX 750 Ti Off| 00000000:03:00.0 Off | N/A | | 42% 32C P8 1W / 52W| 527MiB / 2048MiB | 0% Default | | | | N/A | +-----------------------------------------+----------------------+----------------------+ +---------------------------------------------------------------------------------------+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=======================================================================================| | 0 N/A N/A 277320 C python3 524MiB | +---------------------------------------------------------------------------------------+ Troubleshooting nvidia Disable Nouveau driver if needed\nbash -c \"echo blacklist nouveau  /etc/modprobe.d/blacklist-nvidia-nouveau.conf\" bash -c \"echo options nouveau modeset=0  /etc/modprobe.d/blacklist-nvidia-nouveau.conf\" update-initramfs -u update-grub reboot Stable Diffusion web UI Thanks to AUTOMATIC1111 made everything so easy.\nAlthough, I am aware of both cmdr2’s and InvokeAI’s project, but AUTOMATIC1111’s is the most mature and supported.\nRun this script with user account to install:\nbash It may returns some errors on non-GPU devices and that’s fine.\nGo into the SD’s directory:\ncd stable-diffusion-webui/\nEdit #export COMMANDLINE_ARGS=\"\" line in the config file:\nnano webui-user.sh\nFor old GPU (like my 750ti):\nexport COMMANDLINE_ARGS=\"--lowvram --listen --xformers --always-batch-cond-uncond --opt-split-attention --enable-insecure-extension-access\" export PYTORCH_CUDA_ALLOC_CONF=\"garbage_collection_threshold:0.6,max_split_size_mb:24\" For CPU only:\nexport COMMANDLINE_ARGS=\"--listen --skip-torch-cuda-test --use-cpu all --no-half --no-half-vae --opt-split-attention --enable-insecure-extension-access\" Then run ./webui.sh to start\nNote: Even with those optimization commands above, it may still get CUDA out of memory error under heavy load. Cases could be:\n Sending to img2img/inpaint/sketch back and forth Increasing Batch size or Width/Height Using SD upscale script with large Batch count Using large size ControlNet models (only with control_*.safetensors, coadapter-*.pth and t2iadapter_*.safetensors work fine even with muli-controlnet)  Working with caution can avoid the issue most of the time. When CUDA out of memory occurs, just refresh the web page and generate again. If it persist, go to SSH, Ctrl+C to terminate webui process and ./webui.sh to restart.\nHowever, when I need to use those large controlnet models, such as normal,hed,mlsd and scribble. I have to switch the COMMANDLINE_ARGS into CPU only. By this way, cpu mode can handle larger model and heavier load by using RAM as VRAM. Therefore, the capacity increases from 2GB to 16GB at the cost of slow generating.\nBasic Usage   Open the IP 192.168.1.x:7860 from a modern browser to start using SD.\n  From the SD server machine or through SSH, run watch -n 2 nvidia-smi to monitor the GPU status. For CPU usage, simply use top or apt install bpytop then bpytop.\n  Go to Civitai and Hugging Face to find and download models. Use wget or git-lfs to download models via SSH directly onto the server. Or use scp/rsync/sftp/syncthing to transfer files between local and remote.\n  For Civitai, right click Download button and Copy Link, then go to SSH run wget https://civitai.com/api/download/models/xxxxx --content-disposition. For Hugging Face, just use ‘wget’ with raw file link.\n  For example, if you want to batch download a collection of anime models, use git clone https://huggingface.co/AIARTCHAN/aichan_blend then mv aichan_blend/*.safetensors stable-diffusion-webui/models/Stable-diffusion/\n  To batch download ControlNet models, use git clone https://huggingface.co/webui/ControlNet-modules-safetensors then mv T2I-Adapter/models/*.safetensors stable-diffusion-webui/extensions/sd-webui-controlnet/models/\n  Go to the official wiki to find and download extensions or use the webui built-in extensions page.\n  Use git pull to update the webui when needed.\n  Manage/remove styles by nano stable-diffusion-webui/styles.csv\n  Learn more from the SD RESOURCE GOLDMINE and Educational MegaGrid.\n  ControlNet Learn everything from these:\n ControlNet: Control human pose in Stable Diffusion A1111 ControlNet extension - explained like you’re 5 Dummy ControlNet guide NEXT-GEN MULTI-CONTROLNET INPAINTING  Preprocessor and Model Combinations:\ncanny - control_canny - t2iadapter_canny mlsd - control_mlsd hed - control_hed scribble - control_scribble - t2iadapter_sketch fake_scribble - control_scribble - t2iadapter_sketch openpose - control_openpose - t2iadapter_openpose - t2iadapter_keypose openpose_hand - control_openpose - t2iadapter_openpose segmentation - control_seg - t2iadapter_seg depth - control_depth - t2iadapter_depth depth_leres - control_depth - t2iadapter_depth depth_leres_boost - control_depth - t2iadapter_depth normal_map - control_normal binary - control_scribble - t2iadapter_sketch color - t2iadapter_color pidinet - control_hed clip_vision - t2iadapter_style Self-Healing Daemon To make webui auto restart in the background when it crashes, we need to use another script. Thanks to this guide.\nnano webuid.sh\n#!/bin/bash #Scripts to restart services if not running ps -ef | grep python3 |grep -v grep  /dev/null if [ $? != 0 ] then echo \"restarting sd-webui\" \u0026\u0026 cd /home/$username/stable-diffusion-webui \u0026\u0026 ./webui.sh fi sudo chmod 755 /home/$username/stable-diffusion-webui/webuid.sh\nRun ./webuid.sh to test it\nEdit crontab -e to make it auto start\n@reboot /home/$username/stable-diffusion-webui/webuid.sh */1 * * * * /home/$username/stable-diffusion-webui/webuid.sh PS: This script may conflicts with other python tools such as bpytop, so using top instead.\nTo see the output from webui.sh, put exec \u0026 (tee -a \"webui.log\") in the beginning of webui-user.sh, use tail -f webui.log to see it like before, and use pkill python3 to force restart it.\n",
  "wordCount" : "2127",
  "inLanguage": "en",
  "datePublished": "2023-03-28T00:00:00Z",
  "dateModified": "2023-03-28T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Jun"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://techshinobi.org/posts/cheapsd/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Tech Shinobi",
    "logo": {
      "@type": "ImageObject",
      "url": "https://techshinobi.org/favicon.ico"
    }
  }
}
</script>
</head>

<body class=" dark" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://techshinobi.org/" accesskey="h" title="Tech Shinobi (Alt + H)">Tech Shinobi</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="https://techshinobi.org/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://techshinobi.org/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="https://techshinobi.org/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://techshinobi.org/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://techshinobi.org/">Home</a>&nbsp;»&nbsp;<a href="https://techshinobi.org/posts/">Posts</a></div>
    <h1 class="post-title">
      Cheapskate&#39;s Stable Diffusion Server
    </h1>
    <div class="post-meta"><span title='2023-03-28 00:00:00 +0000 UTC'>March 28, 2023</span>&nbsp;·&nbsp;10 min&nbsp;·&nbsp;Jun

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#no-dall-e-no-midjourney-and-no-colab" aria-label="No DALL-E, No Midjourney and No Colab">No DALL-E, No Midjourney and No Colab</a></li>
                <li>
                    <a href="#hardware" aria-label="Hardware">Hardware</a><ul>
                        
                <li>
                    <a href="#requirements" aria-label="Requirements">Requirements</a></li>
                <li>
                    <a href="#my-mini-server-build" aria-label="My mini Server Build">My mini Server Build</a></li>
                <li>
                    <a href="#asuka-benchmark" aria-label="Asuka Benchmark">Asuka Benchmark</a></li></ul>
                </li>
                <li>
                    <a href="#installation" aria-label="Installation">Installation</a><ul>
                        
                <li>
                    <a href="#debian-linux" aria-label="Debian Linux">Debian Linux</a><ul>
                        
                <li>
                    <a href="#troubleshooting-nic" aria-label="Troubleshooting NIC">Troubleshooting NIC</a></li></ul>
                </li>
                <li>
                    <a href="#nvidia-driver-and-cuda-toolkit" aria-label="NVIDIA Driver and CUDA Toolkit">NVIDIA Driver and CUDA Toolkit</a><ul>
                        
                <li>
                    <a href="#troubleshooting-nvidia" aria-label="Troubleshooting nvidia">Troubleshooting nvidia</a></li></ul>
                </li>
                <li>
                    <a href="#stable-diffusion-web-ui" aria-label="Stable Diffusion web UI">Stable Diffusion web UI</a></li></ul>
                </li>
                <li>
                    <a href="#basic-usage" aria-label="Basic Usage">Basic Usage</a><ul>
                        
                <li>
                    <a href="#controlnet" aria-label="ControlNet">ControlNet</a></li>
                <li>
                    <a href="#self-healing-daemon" aria-label="Self-Healing Daemon">Self-Healing Daemon</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="no-dall-e-no-midjourney-and-no-colab">No DALL-E, No Midjourney and No Colab<a hidden class="anchor" aria-hidden="true" href="#no-dall-e-no-midjourney-and-no-colab">#</a></h2>
<p>This is a guide showing how to build your own stable diffusion server on what you already have or cheap used hardwares. It may not satisfy for a serious production use but pretty viable for learning, testing or casual use.</p>
<p>Before we start, here&rsquo;s some comments on OpenAI:</p>
<ul>
<li><a href="https://www.businessinsider.com/history-of-openai-company-chatgpt-elon-musk-founded-2022-12">The history of ChatGPT creator OpenAI, which Elon Musk helped found before parting ways and criticizing</a></li>
<li><a href="https://www.vice.com/en/article/5d3naz/openai-is-now-everything-it-promised-not-to-be-corporate-closed-source-and-for-profit">OpenAI Is Now Everything It Promised Not to Be: Corporate, Closed-Source, and For-Profit</a></li>
<li><a href="https://scribe.nixnet.services/geekculture/will-chatgpt-be-open-source-4b2928d57a2">Will ChatGPT be open source?</a></li>
<li><a href="https://www.theregister.com/2023/03/24/column/">ChatGPT, how did you get here? It was a long journey through open source AI</a></li>
<li><a href="https://tcrn.ch/3MKBD5P">When big AI labs refuse to open source their models, the community steps in</a></li>
<li><a href="https://youtu.be/Sqa8Zo2XWc4">Artificial Intelligence: Last Week Tonight with John Oliver (HBO)</a></li>
<li><a href="https://youtu.be/hZTv-R6E32Y">The TRUTH about OpenAI</a></li>
</ul>
<p>I have been using ChatGPT and its API regulary. Since my <a href="https://techshinobi.org/posts/bypass-chatgpt/">last post</a>, the API has been upgraded to gpt-3.5-turbo which broke my program and gpt-4 seems coming up soon. Therefore, I may not fix my code proactively.</p>
<p>I also built a customized chatbot project which was running on the web version of ChatGPT. However, one day it suddenly got blocked by OpenAI&rsquo;s cloudflare filter.</p>
<p>I believe that was done on purpose —by tightening up the IP range of all popular VPN providers. I have to switch over to a proxy login endpoint <code>https://bypass.duti.tech/api/</code>, thanks to <a href="https://github.com/acheong08/ChatGPT">acheong08&rsquo;s Reverse engineered ChatGPT API</a>. By doing this, it compromises some of security but it&rsquo;s better than using the paid API.</p>
<p>The reason why I keep trying this route is not just for saving money, but to counter attack <a href="https://cheapskatesguide.org/articles/real-computer-game.html">against the Big Tech companies</a>.</p>
<p>There are <a href="https://github.com/nichtdax/awesome-totally-open-chatgpt">a list of alternatives</a> to OpenAI&rsquo;s GPT. I would like to test <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a> sometime, as it can <a href="https://simonwillison.net/2023/Mar/11/llama/">run on as low-profile as a Raspberry Pi</a>.</p>
<p>The stand I&rsquo;m taking is simple. I love the technology but I have problem with big tech company. I&rsquo;ll work against it unless the product goes truly open source and their business model goes nonprofit —because neutrality and transparency is crucial for such technology.</p>
<p>AI itself is not a threat but the capital behind it.</p>
<h2 id="hardware">Hardware<a hidden class="anchor" aria-hidden="true" href="#hardware">#</a></h2>
<h3 id="requirements">Requirements<a hidden class="anchor" aria-hidden="true" href="#requirements">#</a></h3>
<p>This article is for both old GPUs and CPU. If using a GPU, make sure it supports FP16. Otherwise, just run it on CPU regardless because it will run into VRAM issues.</p>
<blockquote>
<p>2GB or larger Nvidia card of Maxwell 1 (745, 750, and 750ti)</p>
</blockquote>
<p>According to <a href="https://rentry.org/stablediffgpubuy">this buying guide</a>, my spare GTX 750 Ti with 2GB VRAM is the oldest GPU that supports FP16.</p>
<p>RAM size should be larger than 8GB. According to my test, 4GB won&rsquo;t even run and 8GB works only with small models. So 12~16GB is the minimum for non-testing.</p>
<p>Hard drive is not important, minimum is 20GB (debian clean install + base sd-webui + 2 pruned models).</p>
<p>Using SSD can increase the speed of loading weights (switching models) but not the generating speed.</p>
<h3 id="my-mini-server-build">My mini Server Build<a hidden class="anchor" aria-hidden="true" href="#my-mini-server-build">#</a></h3>
<p>Because of the 2GB VRAM on 750ti is barely enough for real production (Restore faces+Hires. fix+VAE+LoRA+multi-ControlNet+inpainting+upscaling). After working for hours, SD crashes quite often. Therefore, I had to heavily rely on <a href="#self-healing-daemon">my Self-Healing Daemon</a>.</p>
<p>Finally, I decided to build a dedicated GPU server which is smaller and more capable for various AI projects.</p>
<ul>
<li>HP Z2 G4 Mini Workstation - $85
<ul>
<li>Barebones w/o AC adapter</li>
<li>C246 Chipset</li>
<li>w/ P600 Mobile GPU (rare 4GB version)</li>
</ul>
</li>
<li>HP 230W Power Supply - $18
<ul>
<li>19.5V 11.8A</li>
<li>7.4mm x 5.0mm Connector</li>
<li>HSTNN-xxxx for EliteBook Mobile Workstations</li>
</ul>
</li>
<li>Intel Pentium Gold G5420 $22
<ul>
<li>3.8 GHz 2 cores 4 threads 54W</li>
<li>LGA1151 revision 2 for Coffee Lake</li>
</ul>
</li>
<li>Spare RAM sticks - $0/$40
<ul>
<li>DDR4 16+4GB 2133MHz SODIMM</li>
</ul>
</li>
<li>Spare SSD - $0/$30
<ul>
<li>512GB NVMe M.2 2280</li>
</ul>
</li>
</ul>
<p>Total cost for me is about $120. For buying everything from scratch would be around $200.</p>
<p>Note:</p>
<ul>
<li>These are all used parts on ebay, so price and availability changes quite a bit.</li>
<li>Performance should be similar between different Pascal mobile GPUs, e.g. Quadro P500, P520, P600, P620, P1000, MX1x0 and GTX10x0. Even between Maxwell (750ti) and Pascal (P600), I don&rsquo;t gain noticible speed improvement but doubled VRAM for capability.</li>
<li>CPU does not matter for SD running on GPU mode. So Pentium/Celeron is good enough for generating images. However, using tensorflow based tools like Dreambooth (for training) requires CPU to support AVX Instructions. In this case, i3-8100 or Xeon E-2124 (more $$) can be considered, however, software workaround is also available for tinkers. Although I don&rsquo;t intend to do any training on this build.</li>
<li>Creativity takes time to think and plan before take the shot. People who like spray and pray tend to spend more and hope for the best but it&rsquo;s far from the way. Both bolt-action and full-auto have their value, but I&rsquo;d perfer doing it just right.</li>
</ul>
<h3 id="asuka-benchmark">Asuka Benchmark<a hidden class="anchor" aria-hidden="true" href="#asuka-benchmark">#</a></h3>
<p>If you don&rsquo;t understand the naming, never mind, it&rsquo;s just the &ldquo;hello world&rdquo; test for SD, a.k.a. &ldquo;hello asuka&rdquo; test.</p>
<p>This was the gold standard in <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/2017">the community</a>.</p>
<pre tabindex="0"><code>Sampler: Euler
Seed: 2870305590
CFG: 12
Resolution: 512x512
Prompt: masterpiece, best quality, masterpiece, asuka langley sitting cross legged on a chair
Negative Prompt: lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts,signature, watermark, username, blurry, artist name
</code></pre><p>Results:</p>
<ul>
<li>Run on Quadro P600 (384CUDA4G) - 0:56 per asuka, 2.80s/it</li>
<li>Run on GTX 750 Ti (640CUDA2G) - 1:09 per asuka, 3.47s/it</li>
<li>Run on E5-2670 (8C16T) - 3:45 per asuka, 10s/it</li>
<li>Run on E3-1245 (4C8T) - 5:30 per asuka, 16s/it</li>
<li>Run on i5-2300 (4C4T) - 6:40 per asuka, 20s/it</li>
<li>Run on i5-2520M (2C4T) - 12:30 per asuka, 37s/it</li>
<li>Run on G5420 (2C4T) - 12:50 per asuka, 38s/it</li>
</ul>
<h2 id="installation">Installation<a hidden class="anchor" aria-hidden="true" href="#installation">#</a></h2>
<h3 id="debian-linux">Debian Linux<a hidden class="anchor" aria-hidden="true" href="#debian-linux">#</a></h3>
<p>Why Linux?</p>
<p>Because it runs efficient and open-source.</p>
<p>Why Debian?</p>
<p>I&rsquo;ve tried RPM distros and that didn&rsquo;t went well. Then I found <a href="https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh">the script says</a>:</p>
<blockquote>
<p>Tested on Debian 11 (Bullseye)</p>
</blockquote>
<p>So just go to <a href="https://www.debian.org/download">debian.org</a> and get <code>debian-11.6.0-amd64-netinst.iso</code></p>
<p>Use <a href="https://www.balena.io/etcher">Etcher</a> or <a href="https://rufus.ie/en/">Rufus</a> to flash the ISO file into a USB drive</p>
<p>Boot into the USB installer we just created and select <code>Graphical install</code></p>
<p>Before going into the network configuring step, connect the Ethernet cable so this can let it configure network interfaces automatically.</p>
<p>After setup root and user credentials, I used entire disk while partitioning since this device is dedicated for SD.</p>
<p>Other steps are good by default. Except software selection.</p>
<p><strong>Do not install any desktop environment</strong> since it may cause trouble while installing graphics driver later on.</p>
<p>Enable SSH server because we want to use SD from other machines within a local network.</p>
<p>While installing GRUB, in my case the HDD is <code>/dev/sda</code>.</p>
<p>After installation finish and reboot, log in with root account.</p>
<p>Run <code>apt-get install sudo -y</code> then <code>usermod -aG sudo username</code> to add the user account as sudoer. Reboot to apply this change.</p>
<p>Run <code>ip a</code> to get the IP address, in my case the ethernet is <code>enp0s25</code>.</p>
<p>Use <a href="https://mremoteng.org/">mRemoteNG</a>, <a href="https://remmina.org/">Remmina</a> or terminal to SSH into the SD dedicated machine <strong>from a daily driver computer</strong>.</p>
<p>Install the dependencies:</p>
<pre tabindex="0"><code>apt install wget git python3 python3-venv libgl1 git-lfs libglib2.0-0
</code></pre><h4 id="troubleshooting-nic">Troubleshooting NIC<a hidden class="anchor" aria-hidden="true" href="#troubleshooting-nic">#</a></h4>
<p>If the ethernet doesn&rsquo;t work, saying something like &ldquo;Missing firmware rtl81xxxxx.fw&rdquo;, then we will need to install <a href="https://packages.debian.org/bullseye/all/firmware-realtek/download">firmware-realtek</a> driver package.</p>
<p>Download <code>firmware-realtek_20210315-3_all.deb</code> from another machine, copy it to a USB drive and plug in.</p>
<p>Run <code>lsblk</code> to confirm the USB drive is <code>sdb1</code> then</p>
<p><code>mount /dev/sdb1 /mnt</code></p>
<p><code>cd /mnt</code></p>
<p><code>apt install /mnt/firmware-realtek_20210315-3_all.deb</code></p>
<p>After installing the driver, we need to make sure the network config is right.</p>
<p><code>nano /etc/network/interfaces</code></p>
<pre tabindex="0"><code>auto enp2s0
allow-hotplug eth0
iface enp2s0 inet dhcp
</code></pre><p>Run <code>systemctl restart networking</code> then <code>ip a</code> the network connection should be working now.</p>
<p>Use <code>umount /mnt</code> to eject the USB drive.</p>
<h3 id="nvidia-driver-and-cuda-toolkit">NVIDIA Driver and CUDA Toolkit<a hidden class="anchor" aria-hidden="true" href="#nvidia-driver-and-cuda-toolkit">#</a></h3>
<p>I didn&rsquo;t follow <a href="https://wiki.debian.org/NvidiaGraphicsDrivers#Debian_11_.22Bullseye.22">debian wiki</a> to install the driver. By that way, it will install stable version 470 but we can install latest 530 with <a href="https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;target_arch=x86_64&amp;Distribution=Debian&amp;target_version=11&amp;target_type=runfile_local">CUDA Toolkit</a>.</p>
<pre tabindex="0"><code>wget https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda_12.1.0_530.30.02_linux.run

apt install linux-headers-`uname -r` build-essential libglu1-mesa-dev libx11-dev libxi-dev libxmu-dev -y

chmod +x cuda_12.1.0_530.30.02_linux.run

sh cuda_12.1.0_530.30.02_linux.run
</code></pre><p>Select Driver and Toolkit, after installation run <code>nvidia-smi</code> to verify:</p>
<pre tabindex="0"><code>+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce GTX 750 Ti       Off| 00000000:03:00.0 Off |                  N/A |
| 42%   32C    P8                1W /  52W|    527MiB /  2048MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+

+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A    277320      C   python3                                     524MiB |
+---------------------------------------------------------------------------------------+
</code></pre><h4 id="troubleshooting-nvidia">Troubleshooting nvidia<a hidden class="anchor" aria-hidden="true" href="#troubleshooting-nvidia">#</a></h4>
<p>Disable Nouveau driver if needed</p>
<pre tabindex="0"><code>bash -c &#34;echo blacklist nouveau &gt; /etc/modprobe.d/blacklist-nvidia-nouveau.conf&#34;
bash -c &#34;echo options nouveau modeset=0 &gt;&gt; /etc/modprobe.d/blacklist-nvidia-nouveau.conf&#34;
update-initramfs -u
update-grub
reboot
</code></pre><h3 id="stable-diffusion-web-ui">Stable Diffusion web UI<a hidden class="anchor" aria-hidden="true" href="#stable-diffusion-web-ui">#</a></h3>
<p>Thanks to <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui">AUTOMATIC1111</a> made everything so easy.</p>
<p>Although, I am aware of both <a href="https://github.com/cmdr2/stable-diffusion-ui">cmdr2&rsquo;s</a> and <a href="https://github.com/invoke-ai/InvokeAI">InvokeAI&rsquo;s</a> project, but AUTOMATIC1111&rsquo;s is the most mature and supported.</p>
<p>Run this script with user account to install:</p>
<pre tabindex="0"><code>bash &lt;(wget -qO- https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh)
</code></pre><p>It may returns some errors on non-GPU devices and that&rsquo;s fine.</p>
<p>Go into the SD&rsquo;s directory:</p>
<p><code>cd stable-diffusion-webui/</code></p>
<p>Edit <code>#export COMMANDLINE_ARGS=&quot;&quot;</code> line in the config file:</p>
<p><code>nano webui-user.sh</code></p>
<p>For old GPU (like my 750ti):</p>
<pre tabindex="0"><code>export COMMANDLINE_ARGS=&#34;--lowvram --listen --xformers --always-batch-cond-uncond --opt-split-attention --enable-insecure-extension-access&#34;

export PYTORCH_CUDA_ALLOC_CONF=&#34;garbage_collection_threshold:0.6,max_split_size_mb:24&#34;
</code></pre><p>For CPU only:</p>
<pre tabindex="0"><code>export COMMANDLINE_ARGS=&#34;--listen --skip-torch-cuda-test --use-cpu all --no-half --no-half-vae --opt-split-attention --enable-insecure-extension-access&#34;
</code></pre><p>Then run <code>./webui.sh</code> to start</p>
<p>Note: Even with those optimization commands above, it may still get <code>CUDA out of memory</code> error under heavy load.
Cases could be:</p>
<ul>
<li><code>Sending to img2img/inpaint/sketch</code> back and forth</li>
<li>Increasing <code>Batch size</code> or <code>Width/Height</code></li>
<li>Using <code>SD upscale</code> script with large <code>Batch count</code></li>
<li>Using large size ControlNet models (only with <code>control_*.safetensors</code>, <code>coadapter-*.pth</code> and <code>t2iadapter_*.safetensors</code> work fine even with muli-controlnet)</li>
</ul>
<p>Working with caution can avoid the issue most of the time. When <code>CUDA out of memory</code> occurs, just refresh the web page and generate again. If it persist, go to SSH, <code>Ctrl+C</code> to terminate webui process and <code>./webui.sh</code> to restart.</p>
<p>However, when I need to use those large controlnet models, such as <code>normal</code>,<code>hed</code>,<code>mlsd</code> and <code>scribble</code>. I have to switch the <code>COMMANDLINE_ARGS</code> into CPU only. By this way, cpu mode can handle larger model and heavier load by using RAM as VRAM. Therefore, the capacity increases from 2GB to 16GB at the cost of slow generating.</p>
<h2 id="basic-usage">Basic Usage<a hidden class="anchor" aria-hidden="true" href="#basic-usage">#</a></h2>
<ul>
<li>
<p>Open the IP <code>192.168.1.x:7860</code> from a modern browser to start using SD.</p>
</li>
<li>
<p>From the SD server machine or through SSH, run <code>watch -n 2 nvidia-smi</code> to monitor the GPU status. For CPU usage, simply use <code>top</code> or <code>apt install bpytop</code> then <code>bpytop</code>.</p>
</li>
<li>
<p>Go to <a href="https://civitai.com/">Civitai</a> and <a href="https://huggingface.co/">Hugging Face</a> to find and download models. Use <code>wget</code> or <code>git-lfs</code> to download models via SSH directly onto the server. Or use scp/rsync/sftp/syncthing to transfer files between local and remote.</p>
</li>
<li>
<p>For Civitai, right click Download button and Copy Link, then go to SSH run <code>wget https://civitai.com/api/download/models/xxxxx --content-disposition</code>. For Hugging Face, just use &lsquo;wget&rsquo; with raw file link.</p>
</li>
<li>
<p>For example, if you want to batch download a collection of anime models, use <code>git clone https://huggingface.co/AIARTCHAN/aichan_blend</code> then <code>mv aichan_blend/*.safetensors stable-diffusion-webui/models/Stable-diffusion/</code></p>
</li>
<li>
<p>To batch download ControlNet models, use <code>git clone https://huggingface.co/webui/ControlNet-modules-safetensors</code> then <code>mv T2I-Adapter/models/*.safetensors stable-diffusion-webui/extensions/sd-webui-controlnet/models/</code></p>
</li>
<li>
<p>Go to the <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Extensions">official wiki</a> to find and download extensions or use the webui built-in extensions page.</p>
</li>
<li>
<p>Use <code>git pull</code> to update the webui when needed.</p>
</li>
<li>
<p>Manage/remove styles by <code>nano stable-diffusion-webui/styles.csv</code></p>
</li>
<li>
<p>Learn more from the <a href="https://rentry.org/sdgoldmine">SD RESOURCE GOLDMINE</a> and <a href="https://sd.mcmonkey.org/megagrid/">Educational MegaGrid</a>.</p>
</li>
</ul>
<h3 id="controlnet">ControlNet<a hidden class="anchor" aria-hidden="true" href="#controlnet">#</a></h3>
<p>Learn everything from these:</p>
<ul>
<li><a href="https://stable-diffusion-art.com/controlnet/">ControlNet: Control human pose in Stable Diffusion</a></li>
<li><a href="https://www.reddit.com/r/StableDiffusion/comments/119o71b/a1111_controlnet_extension_explained_like_youre_5/">A1111 ControlNet extension - explained like you&rsquo;re 5</a></li>
<li><a href="https://rentry.co/dummycontrolnet">Dummy ControlNet guide</a></li>
<li><a href="https://www.youtube.com/watch?v=MDHC7E6G1RA">NEXT-GEN MULTI-CONTROLNET INPAINTING</a></li>
</ul>
<p>Preprocessor and Model Combinations:</p>
<pre tabindex="0"><code>canny -&gt; control_canny - t2iadapter_canny
mlsd -&gt; control_mlsd
hed -&gt; control_hed
scribble -&gt; control_scribble - t2iadapter_sketch
fake_scribble -&gt; control_scribble - t2iadapter_sketch
openpose -&gt; control_openpose - t2iadapter_openpose - t2iadapter_keypose
openpose_hand -&gt; control_openpose - t2iadapter_openpose
segmentation -&gt; control_seg - t2iadapter_seg
depth -&gt; control_depth - t2iadapter_depth
depth_leres -&gt; control_depth - t2iadapter_depth
depth_leres_boost -&gt; control_depth - t2iadapter_depth
normal_map -&gt; control_normal
binary -&gt; control_scribble - t2iadapter_sketch
color -&gt; t2iadapter_color
pidinet -&gt; control_hed
clip_vision -&gt; t2iadapter_style
</code></pre><h3 id="self-healing-daemon">Self-Healing Daemon<a hidden class="anchor" aria-hidden="true" href="#self-healing-daemon">#</a></h3>
<p>To make webui auto restart in the background when it crashes, we need to use another script. Thanks to <a href="https://geekflare.com/auto-restart-services-when-down/">this guide</a>.</p>
<p><code>nano webuid.sh</code></p>
<pre tabindex="0"><code>#!/bin/bash
#Scripts to restart services if not running
ps -ef | grep python3 |grep -v grep &gt; /dev/null
if [ $? != 0 ]
then
      echo &#34;restarting sd-webui&#34; &amp;&amp; cd /home/$username/stable-diffusion-webui &amp;&amp; ./webui.sh
fi
</code></pre><p><code>sudo chmod 755 /home/$username/stable-diffusion-webui/webuid.sh</code></p>
<p>Run <code>./webuid.sh</code> to test it</p>
<p>Edit <code>crontab -e</code> to make it auto start</p>
<pre tabindex="0"><code>@reboot /home/$username/stable-diffusion-webui/webuid.sh
*/1 * * * * /home/$username/stable-diffusion-webui/webuid.sh
</code></pre><p>PS: This script may conflicts with other python tools such as <code>bpytop</code>, so using <code>top</code> instead.</p>
<p>To see the output from <code>webui.sh</code>, put <code>exec &amp;&gt; &gt;(tee -a &quot;webui.log&quot;)</code> in the beginning of <code>webui-user.sh</code>, use <code>tail -f webui.log</code> to see it like before, and use <code>pkill python3</code> to force restart it.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://techshinobi.org/tags/stablediffusion/">StableDiffusion</a></li>
      <li><a href="https://techshinobi.org/tags/cheapskate/">Cheapskate</a></li>
      <li><a href="https://techshinobi.org/tags/openai/">OpenAI</a></li>
      <li><a href="https://techshinobi.org/tags/opensource/">Opensource</a></li>
      <li><a href="https://techshinobi.org/tags/chatgpt/">ChatGPT</a></li>
      <li><a href="https://techshinobi.org/tags/api/">api</a></li>
      <li><a href="https://techshinobi.org/tags/automatic1111/">AUTOMATIC1111</a></li>
      <li><a href="https://techshinobi.org/tags/debian/">Debian</a></li>
      <li><a href="https://techshinobi.org/tags/script/">script</a></li>
      <li><a href="https://techshinobi.org/tags/self-healing/">Self-Healing</a></li>
      <li><a href="https://techshinobi.org/tags/hardware/">Hardware</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://techshinobi.org/posts/aisecph/">
    <span class="title">« Prev Page</span>
    <br>
    <span>AI CyberSecurity, ChatGPT and Post-humanism</span>
  </a>
  <a class="next" href="https://techshinobi.org/posts/bypass-chatgpt/">
    <span class="title">Next Page »</span>
    <br>
    <span>Bypassing ChatGPT&#39;s Safeguard and Easiest Way to use API</span>
  </a>
</nav>


<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share Cheapskate&#39;s Stable Diffusion Server on twitter"
        href="https://twitter.com/intent/tweet/?text=Cheapskate%27s%20Stable%20Diffusion%20Server&amp;url=https%3a%2f%2ftechshinobi.org%2fposts%2fcheapsd%2f&amp;hashtags=StableDiffusion%2cCheapskate%2cOpenAI%2cOpensource%2cChatGPT%2cAPI%2cAUTOMATIC1111%2cdebian%2cscript%2cSelf-Healing%2chardware">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Cheapskate&#39;s Stable Diffusion Server on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2ftechshinobi.org%2fposts%2fcheapsd%2f&amp;title=Cheapskate%27s%20Stable%20Diffusion%20Server&amp;summary=Cheapskate%27s%20Stable%20Diffusion%20Server&amp;source=https%3a%2f%2ftechshinobi.org%2fposts%2fcheapsd%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Cheapskate&#39;s Stable Diffusion Server on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2ftechshinobi.org%2fposts%2fcheapsd%2f&title=Cheapskate%27s%20Stable%20Diffusion%20Server">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Cheapskate&#39;s Stable Diffusion Server on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2ftechshinobi.org%2fposts%2fcheapsd%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Cheapskate&#39;s Stable Diffusion Server on whatsapp"
        href="https://api.whatsapp.com/send?text=Cheapskate%27s%20Stable%20Diffusion%20Server%20-%20https%3a%2f%2ftechshinobi.org%2fposts%2fcheapsd%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Cheapskate&#39;s Stable Diffusion Server on telegram"
        href="https://telegram.me/share/url?text=Cheapskate%27s%20Stable%20Diffusion%20Server&amp;url=https%3a%2f%2ftechshinobi.org%2fposts%2fcheapsd%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://techshinobi.org/">Tech Shinobi</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
